---
title: "From FASQC to Variant Calling for RNA-Seq"
author: "Anna Quaglieri"
date: "11th October 2017"
output:
  github_document:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: 3
linkcolor: magenta
urlcolor: magenta
---

This is an example workflow from FASTQC to Variant calling using the functions in the *functions* folder.

```{bash engine=bash,eval=FALSE}
git clone git@github.com:annaquaglieri16/RNA-seq-variant-calling.git
```

All the functions used for the variant calling and downsampling pipeline are inside the `./functions` folder. 

## Download RNA-Seq data from GEO

### Get SRX names 

```{r message=FALSE,warning=FALSE}
library(GEOquery)
library(tidyverse)
library(knitr)
library(stringr)
```

Below is an example using one accession number from the Leucegene data.

```{r eval=FALSE}
dir.create("test_data",showWarnings = FALSE,recursive = TRUE)

# Get matrix files for every accession number
series_matrix_info <- function(gse){
gsed <- getGEO(gse,GSEMatrix=TRUE)
gse.mat <- pData(phenoData(gsed[[1]]))
reduced <- gse.mat[,c("title","geo_accession","relation.1")]
write.csv(reduced,file.path("test_data",paste(gse,"_",nrow(gse.mat),".csv",sep="")),row.names = FALSE)
}

series_matrix_info("GSE49642") # 43 samples
```

```{r message=FALSE}
matrix_file <- list.files(path = file.path("test_data"),pattern = "GSE",full.names = TRUE)
GSEmatrix <- read_csv(matrix_file)

GSEmatrix$SRX <- str_extract(string = GSEmatrix$relation.1,pattern = "SRX[0-9][0-9][0-9][0-9][0-9][0-9]")
GSEmatrix$relation.1 <- NULL
kable(head(GSEmatrix))
```

### Create NCBI query

```{r}
search_ncbi <- paste(GSEmatrix$SRX,collapse=" OR ")
search_ncbi
```

Paste the search `r search_ncbi` into NCBI https://www.ncbi.nlm.nih.gov/sra and follow the intructions in https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/#download-sequence-data-files-usi **Download sequence data files using SRA Toolkit** to download all the `SRR` run names and information of the runs. 

```{bash eval=FALSE}
# Files are saved in the home directory under ncbi/public/sra
prefetch --option-file SraAccList_CBF-AML_Leucegene.txt
```

SRA files were converted to `fastq` files with `fastq-dump --split-files`. The command `fastqc` was used to check the quality of the fastq files. The folder `test_data` contains small FASTQ files that can be used as example.

# Downsampling FASTQ files

The [seqtk](https://github.com/lh3/seqtk) tool was used to downsample an exact number of reads from paired end (PE) FASTQ files. The following is just an example command.

```{bash eval=FALSE}
seqtk sample -s100 test_data/SRR1608610_1.fastq.gz 10000 > test_data/sub_SRR1608610_1.fq
seqtk sample -s100 test_data/SRR1608610_2.fastq.gz 10000 > test_data/sub_SRR1608610_2.fq
```

# Define files and programs needed for the pipeline 

* The reference genome **hg19** is used for this analysis.
* Below are all the programs and versions used

```{bash eval=FALSE}
module load STAR/2.5.2
module load R/3.4.3
module load anaconda2/4.0.0
module load sambamba/0.6.6
module load picard-tools/2.9.4
module load gatk/3.7.0
module load varscan/2.3.9
module load vcftools/0.1.13
module load samtools/1.6
module load ensembl-vep/89.0
module load vcflib/1.0.0-rc1
module load vardict/1.5.1
module load freebayes/1.1.0
module load picard-tools/2.9.4
```

* The genome references and annotations used here have been downloaded from [iGenome website](https://support.illumina.com/sequencing/sequencing_software/igenome.html) 

```{bash eval=FALSE}
# Hard link to genome.fa of the reference genome 
genome_fasta=path_to_hg19_genome_directory/genome.fa
# Hard link to gene.gtf where gene annotation is stored
gtf=path_to_hg19_gtf_directory/genes.gtf

# Functions directories
workdir=./functions

# folder where fastq files are stored
fastqdir=./test_data

# STAR folders for one-pass, two-pass and merged output
star_1pass=./aligned_star1
star_2pass=./aligned_star2
star_merged=./star_merged_runs # Every sample comes in different SRR runs which will have to be merged in one SRX sample.
```

# FASTQC

This is just one example to run `fastqc` check on several FASTQ files.

```{bash eval = FALSE}
mkdir -p ${fastqdir}/fastqc
find ${fastqdir} -name "*.fastq.gz" > ./test_data/fastq_files.txt
cat ./test_data/fastq_files.txt | parallel -j 2 "fastqc {} --outdir ${fastqdir}/fastqc"
```

I strongly suggest to have a look at [MultiQC](http://multiqc.info/) which allows you to combine together the results of multiple samples into one compact document. To check which the programs whose output is supported by `MultiQC` and how to install it check their help page.

```{bash eval = FALSE}
multiqc ${fastqdir}/fastqc --interactive -n "FASTQC_summary" -o ${fastqdir}
```

The `FASTQC` reports offer a variety of measures and one can decide about discarding some samples or doing some adapter trimming if necessary. [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) and [Trim Galore!](https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) can be used for this purpose.

I suggest looking at one of my previous analysis around [adapters with STAR and Subread](https://github.com/annaquaglieri16/RNA-Seq-and-adapters--STAR-vs-Subjunc) since they can cause serious troubles with `STAR` default settings.

# Alignement

Once the *fastq* files are ready to be processed we can align them with *STAR*. [Subread/Rsubread](http://subread.sourceforge.net/) is another widely used RNA-Seq aligner. The reason why I initially choose *STAR* over *Subread* was simply due to the fact that *STAR* can generate specific output for chimeric reads that can be directly used with [STAR-Fusion](https://github.com/STAR-Fusion/STAR-Fusion/wiki) to analyse gene fusions as well as because it is part of the [GATK Best Practices to call variants in RNA-Seq](https://gatkforums.broadinstitute.org/gatk/discussion/3892/the-gatk-best-practices-for-variant-calling-on-rnaseq-in-full-detail). 

## Create `STAR` index

`STAR` requires to build an index for the reference genome that will be used in the analysis. We are also going to detect fusions

```{bash eval=FALSE}
# TO BE DELETED
# Create Genome directory where to save STAR Index and STAR Fusion Index folders
star_genome100=path_to_genome_directory/star_index_hg19_99
star_fusion_data=path_to_genome_directory/star_fusion_hg19_dir

mkdir -p ${star_genome100}
mkdir -p ${star_fusion_data}
```


To build the *STAR index* one needs to provide the FASTA file for the reference genome used, a GTF file with information aabout the annotation and STAR also require an an extra parameter called `sjdbOverhang` which is usually set to be *(read length - 1)*. See `STAR` documentation for **Generating genome indexes** in the [STAR manual](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf)
- 99 is (read length - 1) as described in the first section.

Below is a wrapper for `STAR` call to build an index. 

```{r eval=FALSE}
outpud_dir=./
${workdir}/build_STAR_index.sh ${genome_fasta} ${gtf} $outpud_dir "hg19" 99
```

## STAR-1pass

If you are working with a set of bamfiles, STAR developer suggests to run the alignment in a two-pass mode. This consists of first aligning all the bamfiles, collecting the *splice junctions* as output of STAR and realign all the bamfiles with this new information. For more details about 1-pass, 2-pass-multi and 2-pass-single see Section 8 of the [STAR documentation](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf). In my pipeline I normally use the 2-pass multi strategy as below.

```{bash eval=FALSE, echo=FALSE}
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in ${samplein_runs}; do 

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_")
  
  lock=${star_1pass}/${bamout}.lock
  
  if [[ -d ${lock} ]] ; then 
  
    echo "${bamout} is being processed"
    
  continue
    
  else
    
    mkdir -p ${lock}
    
    Rscript ${workdir}/run_STAR.R --genome_index ${star_index} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_1pass} --STARmode "1Pass"
    
    rmdir ${lock}

  fi

done

```


```{bash eval=FALSE, echo=FALSE}
# If HPC is available:
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in $samplein_runs ; do

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_") # to be personalised according to file name

  echo '#!/bin/bash' > ${star_1pass}/${bamout}_align.sh
  echo "#PBS -q submit" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -l nodes=1:ppn=1,mem=1gb" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -N ${bamout}" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -o ${bamout}_out" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -e ${bamout}_err" >> ${star_1pass}/${bamout}_align.sh
  echo  "" >> ${star_1pass}/${bamout}_align.sh
  echo 'module load STAR' >> ${star_1pass}/${bamout}_align.sh
  echo 'module load R' >> ${star_1pass}/${bamout}_align.sh
  
  echo Rscript ${workdir}/run_STAR.R --genome_index ${star_genome100} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_1pass} --STARmode "1Pass" >> ${star_1pass}/${bamout}_align.sh

done


for align in ${star_1pass}/*_align.sh ; do 
  qsub ${align}
done

```


```{bash eval=FALSE}
FQ1=test_data/SRR1608907_1.fastq.gz
FQ2=test_data/SRR1608907_2.fastq.gz

Rscript ./function/run_STAR.R --genome_index star_index_hg19_99 --fastqfiles $FQ1,$FQ2 \
    --sampleName SRR1608907 --outdir ./star_1pass --STARmode "1Pass" 
```

The `R` function above is a wrapper for the STAR call below:

```{bash eval=FALSE}
module add STAR/2.5

STAR --genomeDir path_to_star_index_hg19 \
--readFilesIn $FQ1 $FQ2 --runThreadN 27 --chimSegmentMin 10 --readFilesCommand zcat --alignSJoverhangMin 8 --outBAMcompression 10 --alignSJDBoverhangMin 1 --limitBAMsortRAM 85741557872 --outFilterMismatchNmax 999 --alignIntronMin 20 --alignIntronMax 200000 --alignMatesGapMax 20000 --outFileNamePrefix path_to_star_1pass/SampleName --outSAMtype BAM SortedByCoordinate --outFilterType BySJout --outFilterMultimapNmax 15
```

To see all the arguments available:

```{bash eval=FALSE}
Rscript ./function/run_STAR.R --help
```

After running STAR on all the fastq files available we can collect all the splice junctions from the first pass and use them for the second pass.

```{bash eval=FALSE}
# concatenate splice junctions from all samples from ran in pass1
cat ./star_1pass/*SJ.out.tab > star_1pass/combined_sj.out.tab
# Dobin suggests to remove chrm cause they are usually False positives
awk '!/chrM/' ./star_1pass/combined_sj.out.tab > ./star_1pass/combined_sj_nochrM.out.tab
```

It is suggested to have a look at the summary of the alignment through *MultiQC*.

```{bash eval=FALSE}
multiqc star_1pass --interactive -n "STAR_1passQC" -o ./
```

## STAR-2pass

The second pass alignment is exactly the same as the first one with only a few differences:

- the *sjfile* input created combining the splice junctions from the first pass
- STAR is run with the option of output chimeric reads switched on. This will allow fusion analysis.

The ouput of STAR is a bamfile already sorted by coordinate with the suffix `Aligned.sortedByCoord.out.bam`. At this stage we can also run two more steps `post_align_qc1.sh` and `post_align_qc2.sh`.

```{bash eval=FALSE}
FQ1=test_data/SRR1608907_1.fastq.gz
FQ2=test_data/SRR1608907_2.fastq.gz

Rscript ./function/run_STAR.R --genome_index star_index_hg19_99 --fastqfiles $FQ1,$FQ2 \
    --sampleName SRR1608907 --outdir ./star_2pass --STARmode "2PassMulti" \
    --sjfile ./star_1pass/combined_sj_nochrM.out.tab

# Run featurecounts and collect fragment sizes for QC
./function/post_align_qc1.sh path_to_hg19_genome_directory/genome.fa \
path_to_hg19_gtf_directory/genes.gtf ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam SRR1608907 

# Pre-process bamfile (add Read groups etc..)
./function/post_align_qc2.sh ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam SRR1608907 \
path_to_hg19_genome_directory/genome.fa SRR1608907 >> ${script_dir}/${bamout}_align.sh

```

Details about the two post-alignment functions:

* `post_align_qc1.sh` is optional:

  1. Runs [featureCounts](http://bioinf.wehi.edu.au/featureCounts/) to get gene counts and compute PCA to evaulate the concordance between bamfiles sequenced on different lanes. This allows a QC before merging the different bamfiles into a single one.
  2. Runs [CollectMultipleMetrics](https://broadinstitute.github.io/picard/command-line-overview.html) to collect the fragment distribution of the bamfiles (only possible with PE reads). This is also a good QC to check that the fragment distribution of bamfiles on different lanes is the same. 
  
* `post_align_qc2.sh` contains necessary pre-prcessing steps:

  1. Marks PCR duplicates (using [sambamba markdup](http://lomereiter.github.io/sambamba/docs/sambamba-markdup.html))
  2. Add Read Groups to single runs before merging bamfiles (using [AddOrReplaceReadGroups](https://broadinstitute.github.io/picard/command-line-overview.html)). Even if files do not need to be merges, `GATK` requires read groups to be added bamfiles.
  3. Run [ValidateSamFile](https://broadinstitute.github.io/picard/command-line-overview.html) to check for errors in the final bamfile.

In order, its arguments are:
  
  1. **aligned bamfile**
  2. `SampleName`. This is the name of the sample applied to the `RGID` and `RGPU` fields below.
  4. `SampleName_run`. If a sample was sequenced across different lanes then these needs to be merged in one bamfile but lane-specific reag groups should be added to each separate file. This sample name will be used for the fields `RGLB` and `RGSM` in the `AddOrReplaceReadGroups` groups below.

```{bash eval=FALSE}
# Picard tool function to add read groups to a bamfile
AddOrReplaceReadGroups \
		I= ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam \
		O= ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.RG.bam \
		RGID=SRR1608907 \
		RGPU=SRR1608907 \
		RGLB=SRR1608907_run1 \
		RGPL="illumina" \
		RGSM=SRR1608907_run1
```

After running `post_align_qc2.sh` a file with the suffix `Aligned.reorderedDupl.rg.bam` will be created where read groups are added and PCR duplicated reads marked.


```{bash eval=FALSE,echo=FALSE}
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in $samplein_runs ; do

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_") # to be personalised according to file name

  echo '#!/bin/bash' > ${star_2pass}/${bamout}_align.sh
  echo "#PBS -q submit" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -l nodes=1:ppn=1,mem=1gb" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -N ${bamout}" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -o ${bamout}_out" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -e ${bamout}_err" >> ${star_2pass}/${bamout}_align.sh
  echo  "" >> ${star_2pass}/${bamout}_align.sh
  echo 'module add STAR' >> ${star_2pass}/${bamout}_align.sh
  echo 'module load sambamba' >> ${script_dir}/${bamout}_align.sh
  echo 'module load picard-tools' >> ${script_dir}/${bamout}_align.sh
  echo 'module load R' >> ${script_dir}/${bamout}_align.sh

  echo  Rscript ${workdir}/run_STAR.R --genome_index ${star_genome100} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_2pass} --STARmode "2PassMulti" \
    --sjfile ${star_2pass}/combined_sj_nochrM.out.tab >> ${star_2pass}/${bamout}_align.sh

  ######################################
  # Mark duplicates, addRG and Validate 
  ######################################
  bamin=${star_2pass}/${bamout}Aligned.sortedByCoord.out.bam
  
  echo ${workdir}/post_align_qc1.sh ${genome_fasta} ${gtf} ${bamin} ${bamout} >> ${star_2pass}/${bamout}_align.sh
  
  echo ${workdir}/post_align_qc2.sh ${bamin} ${bamout} ${genome_fasta} ${bamout} >> ${star_2pass}/${bamout}_align.sh


done



```

This time *MultiQC* will give us a summary output also of the fragment distributions and featureCounts if the output files are stored within the `star_2pass` folder.

```{bash eval=FALSE}
multiqc ./star_2pass --interactive -n "STAR_2passQC" -o ./
```

# GATK pre-processing

The pipeline contains function to call variants with `MuTect2`, `Samtools + VarScan2`, `VarDict` and `Freebayes`.
In order to run `MuTect2` some GATK pre-processing are needed. The function `function/gatk_process_pipe.R` will perform the following steps:

* *SplitNCigarReads* see [GATK documentation](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_rnaseq_SplitNCigarReads.php)
* *Base recalibration* see [GATK documentation](https://gatkforums.broadinstitute.org/gatk/discussion/44/base-quality-score-recalibration-bqsr)

Below is an example call which wraps the steps above and check if files have already been created.

```{bash eval=FALSE}
Rscript ./functions/gatk_process_pipe.R \
--reference_fasta path_to_hg19_genome_directory/genome.fa \
--bamfile ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.bam --sampleName SRX381851 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf 
```

The function above is a wrapper for the following `GATK3` calls.

## SplitNCigarReads

```{bash eval=FALSE}
gatk -T SplitNCigarReads -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.bam \
-o ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam \
--filter_mismatching_base_and_quals -U ALLOW_N_CIGAR_READS -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 \
--log_to_file path_to_star_2pass/SRR1608907_RG_DUPL_SPLIT_log
```

## Base recalibration

* Base recalibration using known sites downloaded from the [GATK Bundle](https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle)

```{bash}
module load gatk/3.7.0

gatk -T BaseRecalibrator -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam -nct 8 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf \
-o ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_data.table \
--log_to_file ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_step1_log 

gatk -T BaseRecalibrator -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam -nct 8 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf \
-BQSR path_to_star_2pass/BaseQRecal/SRR1608907/SampleName_recal_data.table \
-o path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
--log_to_file path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_step2_log 

gatk -T AnalyzeCovariates -R path_hg19_reference/genome.fa \
-before path_to_star_2pass/BaseQRecal/SRR1608907/SSRR1608907_recal_data.table \
-after path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
-csv path_to_star_2pass/BaseQRecal/SRR1608907/SSRR1608907_recalibration_plots.csv \
-plots path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recalibration_plots.pdf \
--log_to_file path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_analyseCov_log 

gatk -T PrintReads -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam \
-o ./star_2pass/SRR1608907Recal.reorderedDupl.rg.split.bam \
-nct 8 -BQSR ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
--log_to_file ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_Log_recalibrated_bases
```

# Variant calling

#### Call with MuTect2

The target genes were created using the gene symbols of the mutations listed in **Supplemental Table 3** of LavallÃ©e VP et al 2016. We used the hg19 inbuilt annotation of `Rsubread` to obtain the gene ranges and added 500 bp at the end and at the beginning of each gene.

```{bash eval=FALSE}
module load gatk/3.7.0

gatk -T MuTect2 -R path_hg19_reference/genome.fa \
-I:tumor path_to_star_2pass/SampleName_RG_DUPL_SPLIT_RECALIBRATED.bam \
-L ./Methods/variant_calling_data/target_genes_Lavallee2016.bed \
-o variant_calling_dir/mutect/SampleName_germline_snvs_indels.vcf \
-log variant_calling_dir/mutect/regions/SampleName_germline_snvs_indels_log
```

#### Call with Samtools + VarScan2

```{bash eval=FALSE}
module load varscan/2.3.9
module load samtools/1.6

samtools mpileup --output-tags AD,ADF,ADR,DP,SP \
--fasta-ref -R path_hg19_reference/genome.fa \
-l ./Methods/variant_calling_data/target_genes_Lavallee2016.bed path_to_star_2pass/SampleName_RG_DUPL_SPLIT_RECALIBRATED.bam | varscan mpileup2cns --variants 1 --output-vcf 1 --min-var-freq 0.01 > variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels.vcf 2> variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels_log
```

### Call with VarDict

The `teststrandbias.R` and `var2vcf_valid.pl` scripts were downloaded from https://github.com/AstraZeneca-NGS/VarDict. 

```{bash}
module load vardict/1.5.1

vardict -c 1 -S 2 -E 3 -g 4 -r 2 -t -th 10 -v -G \
-R path_hg19_reference/genome.fa \
-b path_to_star_2pass/SampleName_RG_DUPL.bam ./Methods/variant_calling_data/target_genes_Lavallee2016.bed  | vardict_dir/teststrandbias.R | vardict_dir/var2vcf_valid.pl -N -E -f 0.05 >  variant_calling_dir/vardict/regions/SampleName_germline_snvs_indels.vcf
```

## Annotate variants

Below is an example using the output from VarScan but the same call is used for Mutect2 and VarDict vcf files.

```{bash}
module load ensembl-vep/89.0

vep --dir_cache dir_to_VEP_cache/.vep --offline \
-i variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels.vcf \
-o variant_calling_dir/varscan/regions/annotated_variants/SampleName_germline_annotated.vcf \
--cache --everything --force_overwrite --assembly GRCh37 --fork 12 --vcf --port 3337
```



